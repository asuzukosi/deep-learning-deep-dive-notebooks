{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "Convolutional neural networks are a form of neural network architecture that allow us to keep track of spatial relationship between individual input features. This is particularly useful for images, because to be able to make inference on images you would need to have information of the surrounding pixels on a particular image pixel to be able to identify what the pixel represents. This has made ConvNets the defacto architecture for convolutional neural networks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Layers to Convolutions\n",
    "The journey from fully connected layers to convolutions and why they are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([[0, 1], [3, 4]])\n",
    "a2 = np.array([[0, 1], [2, 3]])\n",
    "mul_result = np.multiply(a1, a2)\n",
    "np.sum(mul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_conv(t1, t2):\n",
    "    mul_result = np.multiply(t1, t2)\n",
    "    return np.sum(mul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_conv(data, kernel):\n",
    "    data_height, data_width = data.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    target = np.zeros(shape=(((data_height-kernel_height)+1), \n",
    "                             ((data_width-kernel_width)+1)))\n",
    "    \n",
    "    \n",
    "    for i in range(0, (data_height-kernel_height)+1):\n",
    "        for j in range(0, (data_width-kernel_width)+1):\n",
    "            temp = input[i:kernel_height+i, j:kernel_width+j]\n",
    "            result = single_conv(temp, kernel)\n",
    "            target[i, j] = result \n",
    "    return target\n",
    "            \n",
    "data = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "kernel = np.array([[0, 1], [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 25.],\n",
       "       [37., 43.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_conv(data, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    # compute 2D cross-correlation\n",
    "    h, w = K.shape\n",
    "    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j].assign(tf.reduce_sum(X[i:i+h, j:j+w] * K))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[19., 25.],\n",
       "       [37., 43.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = tf.constant([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Convolutional Layer in tensorflow\n",
    "We would be looking out how to implment a full convolutional operation layer using the functions we have implemented earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def build(self, kernel_size):\n",
    "        initializer = tf.random_uniform_initializer()\n",
    "        self.weights = self.add_weight(name=\"w\", \n",
    "                                       shape=kernel_size, \n",
    "                                       initializer=initializer)\n",
    "        self.bias = self.add_weight(name=\"b\", shape=(1,), \n",
    "                                    initializer=initializer)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return corr2d(inputs, self.weights) + self.bias "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Edge detection in images\n",
    "We will examine how convolutional neural networks can be used to detect teh objects in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(6, 8) dtype=float32, numpy=\n",
       "array([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [1., 1., 0., 0., 0., 0., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.Variable(tf.ones((6, 8)))\n",
    "X[:, 2:6].assign(tf.zeros(X[:, 2:6].shape))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.constant([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(6, 7) dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross correlation with simple finite edge detector\n",
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(8, 5) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(tf.transpose(X), K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a Kernel\n",
    "As we build larger kernels for deeper layers it would become more difficult to explicitly determine and program the functionality of the kerel. Thereforre we wil use iterative gradient algorithms to learn the parameters of a kernl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 19.738\n",
      "epoch 4, loss 7.252\n",
      "epoch 6, loss 2.831\n",
      "epoch 8, loss 1.136\n",
      "epoch 10, loss 0.461\n"
     ]
    }
   ],
   "source": [
    "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
    "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
    "conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)\n",
    "\n",
    "# The two-dimensional convolutional layer uses four-dimensional input and\n",
    "# output in the format of (example, height, width, channel), where the batch\n",
    "# size (number of examples in the batch) and the number of channels are both 1\n",
    "X = tf.reshape(X, (1, 6, 8, 1))\n",
    "Y = tf.reshape(Y, (1, 6, 7, 1))\n",
    "lr = 3e-2  # Learning rate\n",
    "\n",
    "Y_hat = conv2d(X)\n",
    "for i in range(10):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as g:\n",
    "        g.watch(conv2d.weights[0])\n",
    "        Y_hat = conv2d(X)\n",
    "        l = (abs(Y_hat - Y)) ** 2\n",
    "        # Update the kernel\n",
    "        update = tf.multiply(lr, g.gradient(l, conv2d.weights[0]))\n",
    "        weights = conv2d.get_weights()\n",
    "        weights[0] = conv2d.weights[0] - update\n",
    "        conv2d.set_weights(weights)\n",
    "        if (i + 1) % 2 == 0:\n",
    "            print(f'epoch {i + 1}, loss {tf.reduce_sum(l):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.768\n",
      "epoch 4, loss 0.287\n",
      "epoch 6, loss 0.113\n",
      "epoch 8, loss 0.046\n",
      "epoch 10, loss 0.019\n"
     ]
    }
   ],
   "source": [
    "conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)\n",
    "\n",
    "X = tf.reshape(X, (1, 6, 8, 1))\n",
    "Y = tf.reshape(Y, (1, 6, 7, 1))\n",
    "lr = 3e-2\n",
    "\n",
    "Y_hat = conv2d(X)\n",
    "\n",
    "for i in range(10):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as g:\n",
    "        g.watch(conv2d.weights[0])\n",
    "        Y_hat = conv2d(X)\n",
    "#         # l = (abs(Y_hat - Y)) ** 2\n",
    "#         update = tf.multiply(lr, g.gradient(l, conv2d.weights[0]))\n",
    "#         weights = conv2d.get_weights()\n",
    "#         weights[0] = conv2d.weights[0] - update\n",
    "#         conv2d.set_weights(weights)\n",
    "        \n",
    "#         if (i + 1) %  2 == 0:\n",
    "#             print(f'epoch {i + 1}, loss {tf.reduce_sum(l):.3f}')\n",
    "\n",
    "# for i in range(10):\n",
    "    # with tf.GradientTape(watch_accessed_variables=False) as g:\n",
    "        # g.watch(conv2d.weights[0])\n",
    "        # Y_hat = conv2d(X)\n",
    "        l = (abs(Y_hat - Y)) ** 2\n",
    "        # Update the kernel\n",
    "        update = tf.multiply(lr, g.gradient(l, conv2d.weights[0]))\n",
    "        weights = conv2d.get_weights()\n",
    "        weights[0] = conv2d.weights[0] - update\n",
    "        conv2d.set_weights(weights)\n",
    "        if (i + 1) % 2 == 0:\n",
    "            print(f'epoch {i + 1}, loss {tf.reduce_sum(l):.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
